{smcl}
{com}{sf}{ul off}{txt}{.-}
      name:  {res}ML noML
       {txt}log:  {res}/Users/cjr/Repos/fhi.ml-resource-time.2023/products/log.smcl
  {txt}log type:  {res}smcl
 {txt}opened on:  {res}28 Feb 2023, 11:18:52
{txt}
{com}. 
. // Set up globals.
. do globals/globals
{txt}
{com}. version 16.1
{txt}
{com}. 
. global data_file  "data/raw/Blinded data sheet_310123 - Downloaded 27-02-23.xlsx"
{txt}
{com}. global sheet_name "Data Extraction Form"
{txt}
{com}. global cellrange  A1:AB40
{txt}
{com}. global signature "39:28(17933):3819763061:1092073612"
{txt}
{com}. 
. global random_seed 1234
{txt}
{com}. 
. global report_filename "products/report.docx"
{txt}
{com}. 
. // Define the outcome variables.
. global resource_outcome log_resource1 log_resource2 // TODO: Change to non-log!
{txt}
{com}. // Note: No need to specify outcomes for stset data.
. 
. // Define fixed effect covariate.
. global adj_var i.meta_analysis_planned
{txt}
{com}. 
. // Specify the model for endogeneous treatment assignment.
. // TODO: Check if synthesis_planned corresponds to pre-specification.
. global entreat rec_vs_none = i.field i.synthesis_planned , nointeract
{txt}
{com}. 
{txt}end of do-file

{com}. do globals/analyses
{txt}
{com}. version 16.1
{txt}
{com}. 
. // Define the analyses:
. global analyses             rec_vs_none_resource
{txt}
{com}. global analyses ${c -(}analyses{c )-} // TODO: Add analyses
{txt}
{com}. 
{txt}end of do-file

{com}. do globals/models
{txt}
{com}. version 16.1
{txt}
{com}. 
. // Define the models used in the analyses.
. global rec_vs_none_resource_model eintreg ${c -(}resource_outcome{c )-} ${c -(}adj_var{c )-} , entreat(${c -(}entreat{c )-})
{txt}
{com}. 
{txt}end of do-file

{com}. 
. // Set up Stata.
. do setup/setup
{txt}
{com}. version 16.1
{txt}
{com}. 
. // Set the random number generator seed.
. set rng  mt64s
{txt}
{com}. set seed ${c -(}random_seed{c )-}
{txt}
{com}. set rngstream 1
{txt}
{com}. 
. // Set up Stata's path to use the "packages" directory for add-on packages.
. net set ado "./packages"
{txt}
{com}. sysdir set PERSONAL "./packages"
{txt}
{com}. 
. // Specify formats.
. set cformat %9.2f
{txt}
{com}. set pformat %5.2f
{txt}
{com}. set sformat %8.2f
{txt}
{com}. 
{txt}end of do-file

{com}. 
. // Import and process the data.
. do data/data
{txt}
{com}. version 16.1
{txt}
{com}. 
. // Load the data and check its signature is as expected.
. import excel "${c -(}data_file{c )-}", sheet("${c -(}sheet_name{c )-}") cellrange(${c -(}cellrange{c )-}) firstrow allstring
{res}{text}(28 vars, 39 obs)

{com}. datasignature
  {res}39:28(17933):3819763061:1092073612
{txt}
{com}. assert r(datasignature) == "${c -(}signature{c )-}"
{txt}
{com}. 
. // Define a variable that specifies the product's year.
. tempvar year
{txt}
{com}. rename Year `year'
{res}{txt}
{com}. destring `year', generate(year)
{txt}__000000: all characters numeric; year {res}generated {txt}as {res}int
{txt}
{com}. 
. // Rename and encode the health/welfare variable.
. tempvar field
{txt}
{com}. rename AreaHealthorWelfare `field'
{res}{txt}
{com}. replace `field' = "Healthcare" if `field' == "H"
{txt}variable {bf}__000001{sf} was {bf}{res}str1{sf}{txt} now {bf}{res}str10{sf}
{txt}(19 real changes made)

{com}. replace `field' = "Welface"    if `field' == "W"
{txt}(20 real changes made)

{com}. encode `field' , generate(field)
{txt}
{com}. 
. // Rename and encode the variable that codes for the type of product.
. tempvar product_type
{txt}
{com}. rename Typeofproduct `product_type'
{res}{txt}
{com}. encode `product_type', generate(product_type)
{txt}
{com}. 
. // Rename and encode the variable that codes for whether product is an update.
. tempvar update
{txt}
{com}. rename UpdateYN `update'
{res}{txt}
{com}. replace `update' = strtrim(`update')
{txt}(2 real changes made)

{com}. encode `update', generate(update)
{txt}
{com}. 
. // Rename and encode the variable that codes for whether product is an HTA.
. tempvar hta
{txt}
{com}. rename HTAYorN `hta'
{res}{txt}
{com}. encode `hta', generate(hta)
{txt}
{com}. 
. // Define treatment variables.
. // TODO: Treatment variables will contain valid missing values, e.g. for recommended vs none where some reviews used non-recomended ML.
. local treatments RecommendedvsNone RecommendedvsNonrecom AnyvsNone Recomvsunderuse Recomvsoveruse
{txt}
{com}. local RecommendedvsNone     rec_vs_none   // New variable name.
{txt}
{com}. local RecommendedvsNonrecom rec_vs_nonrec // New variable name.
{txt}
{com}. local AnyvsNone             any_vs_none   // New variable name.
{txt}
{com}. local Recomvsunderuse       rec_vs_under  // New variable name.
{txt}
{com}. local Recomvsoveruse        rec_vs_over   // New variable name.
{txt}
{com}. foreach t of local treatments {c -(}
{txt}  2{com}.   replace `t' = "" if !regexm(`t', "[A-Z]") // Non-missing values are letters in [A-Z]
{txt}  3{com}.   encode  `t', generate(``t'')
{txt}  4{com}.   drop `t'
{txt}  5{com}. {c )-}
{txt}(6 real changes made)
(12 real changes made)
(0 real changes made)
(14 real changes made)
(18 real changes made)

{com}. 
. // Define a value label for analyses that can be prespecified.
. label define planned 0 No 1 Yes
{txt}
{com}. 
. // Define variables that code for prespecified synthesis (any), meta-analysis (incl.
. // quantitative and qualitative), and NMA.
. local planned SynthesisplannednoneYorN SynthesisplannedMetaAnalysis SynthesisplannedNMAYorN
{txt}
{com}. local SynthesisplannednoneYorN     synthesis_planned     // New variable name.
{txt}
{com}. local SynthesisplannedMetaAnalysis meta_analysis_planned // New variable name.
{txt}
{com}. local SynthesisplannedNMAYorN      nma_planned           // New variable name. // TODO: Drop all NMAs from data.
{txt}
{com}. local synthesis_planned_label     "Was any synthesis planned?"
{txt}
{com}. local meta_analysis_planned_label "Was meta-analysis planned?"
{txt}
{com}. local nma_planned_label           "Was NMA planned?"
{txt}
{com}. foreach p of local planned {c -(}
{txt}  2{com}.   generate       ``p'' = 0
{txt}  3{com}.   replace        ``p'' = 1 if `p' != "N" // Works for one values coded "Both".
{txt}  4{com}.   label values   ``p'' planned
{txt}  5{com}.   label variable ``p'' "```p''_label'"
{txt}  6{com}.   drop `p'
{txt}  7{com}. {c )-}
{txt}(20 real changes made)
(18 real changes made)
(0 real changes made)

{com}. 
. // Define a completed variable (analogous to a failure indicator in survival analysis).
. generate          completed = 1
{txt}
{com}. replace           completed = 0 if OngoingYorN == "Y"
{txt}(3 real changes made)

{com}. label    define   completed 0 No 1 Yes
{txt}
{com}. label    values   completed completed
{txt}
{com}. label    variable completed "Report completed?"
{txt}
{com}. drop OngoingYorN
{txt}
{com}. 
. // Define the resource use variable.
. tempvar resource
{txt}
{com}. rename ResourceUsePersonHours `resource'
{res}{txt}
{com}. destring `resource', replace force // One missing outcome. TODO: Note this in the report.
{txt}__000005: contains nonnumeric characters; {res}replaced {txt}as {res}int
{txt}(1 missing value generated)
{res}{txt}
{com}. generate log_resource1 = log(`resource')
{txt}(1 missing value generated)

{com}. generate log_resource2 = log(`resource')
{txt}(1 missing value generated)

{com}. replace  log_resource2 = . if !completed // For right-censored data.
{txt}(3 real changes made, 3 to missing)

{com}. label variable log_resource1 "Resource use (log person-hours)"
{txt}
{com}. label variable log_resource2 "Resource use (log person-hours); possibly censored"
{txt}
{com}. 
. // Define commision date variable.
. tempvar c_day c_month c_year commission
{txt}
{com}. rename CommissionDay131   `c_day'
{res}{txt}
{com}. rename CommissionMonth112 `c_month'
{res}{txt}
{com}. rename CommissionYear2020 `c_year'
{res}{txt}
{com}. generate `commission' = `c_day' + "/" + `c_month' + "/" + `c_year'
{txt}
{com}. generate commission = date(`commission', "DMY")
{txt}
{com}. 
. // Define completion date variable.
. tempvar c_day c_month c_year completion
{txt}
{com}. rename CompletionDay131   `c_day'
{res}{txt}
{com}. rename CompletionMonth112 `c_month'
{res}{txt}
{com}. rename CompletionYear2020 `c_year'
{res}{txt}
{com}. generate `completion' = `c_day' + "/" + `c_month' + "/" + `c_year'
{txt}
{com}. generate completion = date(`completion', "DMY")
{txt}(3 missing values generated)

{com}. // Set right-censoring date for ongoing reviews.
. tempvar max
{txt}
{com}. egen `max' = max(completion)
{txt}
{com}. replace completion = `max' if missing(completion)
{txt}(3 real changes made)

{com}. // TODO: Replace max with the date of the last day of data collection.
. 
. // stset the data.
. stset completion , failure(completed) origin(time commission) scale(7 /*days*/)

     {txt}failure event:  {res}completed != 0 & completed < .
{txt}obs. time interval:  {res}(origin, completion]
{txt} exit on or before:  {res}failure
    {txt}t for analysis:  {res}(time-origin)/7
            {txt}origin:  {res}time commission

{txt}{hline 78}
{res}         39{txt}  total observations
{res}          1{txt}  observation ends on or before enter()
{hline 78}
{res}         38{txt}  observations remaining, representing
{res}         35{txt}  failures in single-record/single-failure data
{res}      1,200{txt}  total analysis time at risk and under observation
                                                at risk from t = {res}        0
                                     {txt}earliest observed entry t = {res}        0
                                          {txt}last observed exit t = {res} 101.8571
{txt}
{com}. 
. // We do not have data on number of downloads or comissioner satisfaction.
. drop Commissionersatisfactionoveral Numberofdownloadstodate
{txt}
{com}. 
. // TODO: Drop other variables with uppercase first letters?
. 
{txt}end of do-file

{com}. 
. // Do estimation.
. do estimation/estimate
{txt}
{com}. version 16.1
{txt}
{com}. 
. // Perform estimation.
. foreach analysis of global analyses {c -(}
{txt}  2{com}.   ${c -(}`analysis'_model{c )-}
{txt}  3{com}.   assert e(converged)
{txt}  4{com}.   estimates store `analysis'
{txt}  5{com}. {c )-}
{res}
{txt}Iteration 0:{space 3}log likelihood = {res:-53.241989}  
Iteration 1:{space 3}log likelihood = {res:-53.235178}  
Iteration 2:{space 3}log likelihood = {res:-53.235122}  
Iteration 3:{space 3}log likelihood = {res:-53.235122}  
{res}
{txt}Extended interval regression{col 49}Number of obs{col 67}= {res}        32
{txt}{col 49}   Uncensored{col 67}= {res}        30
{txt}{col 49}   Left-censored{col 67}= {res}         0
{txt}{col 49}   Right-censored{col 67}= {res}         2
{txt}{col 49}   Interval-cens.{col 67}= {res}         0

{txt}{col 49}Wald chi2({res}2{txt}){col 67}= {res}     14.71
{txt}Log likelihood = {res}-53.235122{txt}{col 49}Prob > chi2{col 67}= {res}    0.0006

{txt}{hline 36}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 37}{c |}      Coef.{col 49}   Std. Err.{col 61}      z{col 69}   P>|z|{col 77}     [95% Con{col 90}f. Interval]
{hline 36}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 14}meta_analysis_planned {c |}
{space 31}Yes  {c |}{col 37}{res}{space 2}     0.98{col 49}{space 2}     0.28{col 60}{space 1}    3.46{col 69}{space 3} 0.00{col 77}{space 4}     0.43{col 90}{space 3}     1.54
{txt}{space 35} {c |}
{space 24}rec_vs_none {c |}
{space 33}H  {c |}{col 37}{res}{space 2}    -1.50{col 49}{space 2}     0.79{col 60}{space 1}   -1.88{col 69}{space 3} 0.06{col 77}{space 4}    -3.05{col 90}{space 3}     0.06
{txt}{space 30}_cons {c |}{col 37}{res}{space 2}     6.06{col 49}{space 2}     0.32{col 60}{space 1}   18.97{col 69}{space 3} 0.00{col 77}{space 4}     5.43{col 90}{space 3}     6.68
{txt}{hline 36}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}rec_vs_none                         {txt}{c |}
{space 30}field {c |}
{space 27}Welface  {c |}{col 37}{res}{space 2}    -1.52{col 49}{space 2}     0.65{col 60}{space 1}   -2.34{col 69}{space 3} 0.02{col 77}{space 4}    -2.80{col 90}{space 3}    -0.25
{txt}{space 35} {c |}
{space 18}synthesis_planned {c |}
{space 31}Yes  {c |}{col 37}{res}{space 2}     1.20{col 49}{space 2}     0.67{col 60}{space 1}    1.79{col 69}{space 3} 0.07{col 77}{space 4}    -0.11{col 90}{space 3}     2.51
{txt}{hline 36}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}/rec_vs_none                        {txt}{c |}
{space 31}cut1 {c |}{col 37}{res}{space 2}     0.27{col 49}{space 2}     0.44{col 77}{space 4}    -0.59{col 90}{space 3}     1.12
{txt}{hline 36}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 16}var(e.log_resource1){c |}{col 37}{res}{space 2}     0.58{col 49}{space 2}     0.16{col 77}{space 4}     0.34{col 90}{space 3}     1.01
{txt}{hline 36}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 1}corr(e.rec_vs_none,e.log_resource1){c |}{col 37}{res}{space 2}     0.17{col 49}{space 2}     0.73{col 60}{space 1}    0.23{col 69}{space 3} 0.81{col 77}{space 4}    -0.86{col 90}{space 3}     0.93
{txt}{hline 36}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}

{com}. 
. // TODO: Based on a comparison of histograms of residuals, QQ plots, and Shapiro-Wilk and Shapiro-Francia tests,
. // TODO: we should model resource use on the
. // TODO: natrual (non-logged) scale. Then we can either present mean difference and/or the ratio.
. 
. // TODO: Plot the Kaplan Meier like so:
. // TODO: The colors and their ordering come from: https://www.stata.com/statalist/archive/2011-02/msg00692.html
. // sts graph , by(rec_vs_none) ci risktable censored(number) ci1opts(fcolor(navy%20)) ci2opts(fcolor(maroon%20))
. 
{txt}end of do-file

{com}. 
. * // Make figures
. * do figures/figures
. 
. * // Obtain the git revision hash, which is used in the reports.
. * tempfile git_revision_filename
. * tempname revision_file
. * shell git rev-parse --short HEAD > "`git_revision_filename'"
. * file open `revision_file' using `git_revision_filename', read text
. * file read `revision_file' line
. * global git_revision = "`macval(line)'"
. 
. * // Make the report.
. * do reports/report
. 
{txt}end of do-file

{com}. est dir

{txt}{hline 13}{c TT}{hline 61}
        name {c |} command      depvar       npar  title 
{hline 13}{c +}{hline 61}
{ralign 12:{stata estimates replay rec_vs_none_resource:rec_vs_non~e}}{col 14}{txt:{c |}}{res}{col 16}{lalign 12:eintreg}{col 29}{lalign 12:mult. depvar}{col 42}  12{col 48}{it:Extended interval regression}
{txt}{hline 13}{c BT}{hline 61}

{com}. estimates replay rec_vs_none_resource

{txt}{hline}
{p 0 8}Model {hi:rec_vs_none_resource}{p_end}
{hline}

Extended interval regression{col 49}Number of obs{col 67}= {res}        32
{txt}{col 49}   Uncensored{col 67}= {res}        30
{txt}{col 49}   Left-censored{col 67}= {res}         0
{txt}{col 49}   Right-censored{col 67}= {res}         2
{txt}{col 49}   Interval-cens.{col 67}= {res}         0

{txt}{col 49}Wald chi2({res}2{txt}){col 67}= {res}     14.71
{txt}Log likelihood = {res}-53.235122{txt}{col 49}Prob > chi2{col 67}= {res}    0.0006

{txt}{hline 36}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 37}{c |}      Coef.{col 49}   Std. Err.{col 61}      z{col 69}   P>|z|{col 77}     [95% Con{col 90}f. Interval]
{hline 36}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 14}meta_analysis_planned {c |}
{space 31}Yes  {c |}{col 37}{res}{space 2}     0.98{col 49}{space 2}     0.28{col 60}{space 1}    3.46{col 69}{space 3} 0.00{col 77}{space 4}     0.43{col 90}{space 3}     1.54
{txt}{space 35} {c |}
{space 24}rec_vs_none {c |}
{space 33}H  {c |}{col 37}{res}{space 2}    -1.50{col 49}{space 2}     0.79{col 60}{space 1}   -1.88{col 69}{space 3} 0.06{col 77}{space 4}    -3.05{col 90}{space 3}     0.06
{txt}{space 30}_cons {c |}{col 37}{res}{space 2}     6.06{col 49}{space 2}     0.32{col 60}{space 1}   18.97{col 69}{space 3} 0.00{col 77}{space 4}     5.43{col 90}{space 3}     6.68
{txt}{hline 36}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}rec_vs_none                         {txt}{c |}
{space 30}field {c |}
{space 27}Welface  {c |}{col 37}{res}{space 2}    -1.52{col 49}{space 2}     0.65{col 60}{space 1}   -2.34{col 69}{space 3} 0.02{col 77}{space 4}    -2.80{col 90}{space 3}    -0.25
{txt}{space 35} {c |}
{space 18}synthesis_planned {c |}
{space 31}Yes  {c |}{col 37}{res}{space 2}     1.20{col 49}{space 2}     0.67{col 60}{space 1}    1.79{col 69}{space 3} 0.07{col 77}{space 4}    -0.11{col 90}{space 3}     2.51
{txt}{hline 36}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}/rec_vs_none                        {txt}{c |}
{space 31}cut1 {c |}{col 37}{res}{space 2}     0.27{col 49}{space 2}     0.44{col 77}{space 4}    -0.59{col 90}{space 3}     1.12
{txt}{hline 36}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 16}var(e.log_resource1){c |}{col 37}{res}{space 2}     0.58{col 49}{space 2}     0.16{col 77}{space 4}     0.34{col 90}{space 3}     1.01
{txt}{hline 36}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{space 1}corr(e.rec_vs_none,e.log_resource1){c |}{col 37}{res}{space 2}     0.17{col 49}{space 2}     0.73{col 60}{space 1}    0.23{col 69}{space 3} 0.81{col 77}{space 4}    -0.86{col 90}{space 3}     0.93
{txt}{hline 36}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}

{com}. 